{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from typing import Any, Dict\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "from langchain.schema.output_parser import StrOutputParser\n",
    "from langchain_community.chat_message_histories import ChatMessageHistory\n",
    "from langchain_core.chat_history import BaseChatMessageHistory\n",
    "from langchain_core.globals import set_debug\n",
    "from langchain_core.runnables import (\n",
    "    RunnableLambda,\n",
    "    RunnablePassthrough,\n",
    "    RunnableSerializable,\n",
    ")\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain_mistralai import ChatMistralAI\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "from prompts.gen_prompts import GENERAL_PROMPT, RAG_PROMPT\n",
    "from rag_pinecone import basic_retriever\n",
    "\n",
    "set_debug(True)\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "google_api_key = os.getenv(\"GOOGLE_API_KEY\")\n",
    "openai_api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "mistralai_api_key = os.getenv(\"MISTRALAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "memory_store = {}\n",
    "\n",
    "gemini_llm = ChatGoogleGenerativeAI(\n",
    "    google_api_key=f\"{google_api_key}\",\n",
    "    model=\"gemini-pro\",\n",
    ")  # Type: Ignore\n",
    "mistral_llm = ChatMistralAI(model=\"mistral-large-latest\")\n",
    "openai_llm = ChatOpenAI(openai_api_key=openai_api_key, model=\"gpt-4o\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_session_history(session_id: str) -> BaseChatMessageHistory:\n",
    "    if session_id not in memory_store:\n",
    "        memory_store[session_id] = ChatMessageHistory()\n",
    "    return memory_store[session_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def baisc_conversation() -> RunnableWithMessageHistory:\n",
    "    basic_convo = GENERAL_PROMPT | openai_llm | StrOutputParser()\n",
    "    with_message_history = RunnableWithMessageHistory(\n",
    "        basic_convo,\n",
    "        get_session_history,\n",
    "        input_messages_key=\"query\",\n",
    "        history_messages_key=\"history\",\n",
    "    )\n",
    "    return with_message_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = await basic_retriever(query=\"Who is Alis?\")\n",
    "print(len(docs))\n",
    "print(docs[0].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever_runnable = RunnableLambda(basic_retriever)\n",
    "basic_convo = RAG_PROMPT | openai_llm | StrOutputParser()\n",
    "\n",
    "with_message_history = RunnableWithMessageHistory(\n",
    "    basic_convo,\n",
    "    get_session_history,\n",
    "    input_messages_key=\"query\",\n",
    "    history_messages_key=\"history\",\n",
    ")\n",
    "query = \"Who is Alis?\"\n",
    "chain = (\n",
    "    {\"context\": retriever_runnable, \"query\": RunnablePassthrough()}\n",
    "    | with_message_history\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "await chain.ainvoke(\"Who is Alis?\", config={\"configurable\": {\"session_id\": \"def234\"}})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def basic_rag_conversation(\n",
    "    query: str, config: Dict[str, Dict[str, Any]]\n",
    ") -> RunnableSerializable:\n",
    "    basic_convo = RAG_PROMPT | openai_llm | StrOutputParser()\n",
    "    with_message_history = RunnableWithMessageHistory(\n",
    "        basic_convo,\n",
    "        get_session_history,\n",
    "        input_messages_key=\"query\",\n",
    "        history_messages_key=\"history\",\n",
    "    )\n",
    "    retriever_runnable = RunnableLambda(basic_retriever)\n",
    "    chain = (\n",
    "        {\"context\": retriever_runnable, \"query\": RunnablePassthrough()}\n",
    "        | with_message_history\n",
    "        | StrOutputParser()\n",
    "    )\n",
    "    response = await chain.ainvoke(query, config)\n",
    "    return response\n",
    "\n",
    "\n",
    "response = basic_rag_conversation(\n",
    "    \"Who is Alis?\", {\"configurable\": {\"session_id\": \"def234\"}}\n",
    ")\n",
    "\n",
    "print(await response)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "yumi-py3.11.8",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
